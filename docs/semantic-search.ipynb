{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98177d1-69d2-4c41-bb96-6fd8e046d75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96129f36-9b0d-4b9b-992a-04a33cde57cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance as ssd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a01fb-4734-4abd-8652-2397a547302f",
   "metadata": {},
   "source": [
    "#### Data dictionary\n",
    "\n",
    "The voice dataset has many different fields. This notebook introduces a semantic search of those fields.\n",
    "\n",
    "Let's first read the the data dictionary into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4516fe-a7c8-4575-9999-839fac386b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcdict = pd.read_csv('bridge2ai-Voice/bridge2ai-voice-corpus-1//b2ai-voice-corpus-1-dictionary.csv')\n",
    "rcdict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1588da5-020a-4878-af12-a1dd8c256618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = rcdict['Field Label'].values.tolist()\n",
    "print(len(sentences))\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e39c4a-fbd6-40e2-bd16-65aa63d36d32",
   "metadata": {},
   "source": [
    "#### Turning sentences into numbers\n",
    "\n",
    "We will use MiniLM model from HuggingFace for generating sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fffdbf-a469-4d75-a162-97004d4b9361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da56a9de-e177-4dbe-8f5c-6d65df612aed",
   "metadata": {},
   "source": [
    "The model has been downloaded from HuggingFace. If you are running this on your own own setup, replace:\n",
    "\n",
    "`'models/sentence-transformers/all-MiniLM-L6-v2' --> 'sentence-transformers/all-MiniLM-L6-v2'`\n",
    "\n",
    "in the two places in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b09ce-2452-4064-8514-4ef64d437696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embed_sentences(text_list):\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained('models/sentence-transformers/all-MiniLM-L6-v2')\n",
    "    model = AutoModel.from_pretrained('models/sentence-transformers/all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(text_list, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)    \n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f890e4be-51ed-4a32-ac76-efdd8772f626",
   "metadata": {},
   "source": [
    "Let's turn all the sentences into embeddings. Vectors that represent aspects of semantic meaning of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a98d25-1637-42ad-94d0-c3d09d37f183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = embed_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce224e-d266-4dfc-8e41-e4b99536f097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(embeddings).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a588cc0-259d-432c-ac6c-b97c27176175",
   "metadata": {},
   "source": [
    "This is where we get to define search query. Feel free to replace the string with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39792e76-741d-428d-956a-6b55e5523d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_string = 'symptoms of depression and anxiety'\n",
    "search_embedding = embed_sentences([search_string,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c442a8-f631-48c9-95c0-1f7c719fb4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute cosine similarity scores for the search string to all other sentences\n",
    "sims = []\n",
    "for embedding in embeddings:\n",
    "    sims.append(1 - ssd.cosine(search_embedding[0], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c521997-c7d7-4ea0-b2aa-4c91ec8b35c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort sentences by similarity score in descending order (the most similar ones are first)\n",
    "sorted_index = np.argsort(sims)[::-1]\n",
    "sentences_sorted = np.array(sentences)[sorted_index]\n",
    "sims = np.array(sims)[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676d81a-e71a-4dd2-bafb-e304440211c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(sims)\n",
    "plt.title(\"Cosine similarity\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c64b55-d486-44af-ade8-a1794acd372d",
   "metadata": {},
   "source": [
    "Select a cutoff value from the figure where you notice a bending of the elbow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21938d4-b7a6-4044-9e60-68aa36c7a590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutoff = 0.3\n",
    "sentences_sorted[sims > cutoff].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2992a6-4597-4147-8096-378364c7e406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
