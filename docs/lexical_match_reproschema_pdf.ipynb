{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import json\n",
    "\n",
    "def extract_text_from_pdfs(directory, output_file):\n",
    "    \"\"\"Extracts text from all PDF files in the given directory and saves it to an output file.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): The path to the directory containing the PDF files.\n",
    "        output_file (str): The path to the output file where the extracted text will be saved.\n",
    "    \n",
    "    Returns:\n",
    "        str: The path to the output file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Output file {output_file} already exists. Returning existing file.\")\n",
    "        return output_file\n",
    "\n",
    "    with open(output_file, 'w') as outfile:  # Use 'w' to create a new file or overwrite an existing one\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.endswith('.pdf'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    print(f\"Extracting text from: {file_path}\")\n",
    "                    with pdfplumber.open(file_path) as pdf:\n",
    "                        for page in pdf.pages:\n",
    "                            text = page.extract_text()\n",
    "                            if text:\n",
    "                                outfile.write(text)\n",
    "                                outfile.write('\\n')\n",
    "    return output_file\n",
    "\n",
    "def check_string_in_file(file_path, search_string):\n",
    "    \"\"\"Checks if a given string is present in a file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the file to be searched.\n",
    "        search_string (str): The string to search for in the file.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the string is found, False otherwise.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "        return search_string in file_content\n",
    "\n",
    "def find_fields_in_directory(directory, field_names):\n",
    "    \"\"\"Finds specified fields in JSON files within a given directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): The path to the directory containing the JSON files.\n",
    "        field_names (list): A list of field names to search for in the JSON files.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping file paths to lists of found field values.\n",
    "    \"\"\"\n",
    "    file_fields = {}\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file != \".gitignore\" and file != \"README.md\":\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    try:\n",
    "                        data = json.load(f)\n",
    "                        fields = []\n",
    "                        for field_name in field_names:\n",
    "                            extract_fields(data, field_name, fields)\n",
    "                        if fields:\n",
    "                            file_fields[file_path] = fields\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON in file: {file_path}\")\n",
    "                    except UnicodeDecodeError:\n",
    "                        print(f\"Encoding error in file: {file_path}\")\n",
    "    \n",
    "    return file_fields\n",
    "\n",
    "def extract_fields(data, field_name, fields):\n",
    "    \"\"\"Recursively extracts specified fields from JSON data.\n",
    "    \n",
    "    Args:\n",
    "        data (dict or list): The JSON data to search through.\n",
    "        field_name (str): The name of the field to extract.\n",
    "        fields (list): The list to append found field values to.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key == field_name:\n",
    "                if isinstance(value, dict):\n",
    "                    for sub_key, sub_value in value.items():\n",
    "                        fields.append(sub_value)\n",
    "                else:\n",
    "                    fields.append(value)\n",
    "            else:\n",
    "                extract_fields(value, field_name, fields)\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            extract_fields(item, field_name, fields)\n",
    "\n",
    "def filter_fields_not_in_file(file_fields, check_file):\n",
    "    \"\"\"Filters out entries where all field values are present in a given file.\n",
    "    \n",
    "    Args:\n",
    "        file_fields (dict): A dictionary mapping file paths to lists of field values.\n",
    "        check_file (str): The path to the file to check the field values against.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A filtered dictionary with entries that have at least one value not present in the file.\n",
    "    \"\"\"\n",
    "    filtered_fields = {}\n",
    "    \n",
    "    for file_path, fields in file_fields.items():\n",
    "        not_in_file_fields = [field for field in fields if not check_string_in_file(check_file, field)]\n",
    "        if not_in_file_fields:\n",
    "            filtered_fields[file_path] = not_in_file_fields\n",
    "            \n",
    "    return filtered_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDFs and save to a file\n",
    "pdf_directory = '/Users/isaacbevers/sensein/reproschema-wrapper/bridge2ai-redcap/data/instrument_pdfs'\n",
    "output_file = 'parsed_redcap_pdfs.txt'\n",
    "output_path = extract_text_from_pdfs(pdf_directory, output_file)\n",
    "print(f\"Text extracted to: {output_path}\")\n",
    "\n",
    "# Find fields in JSON files and filter against the parsed text\n",
    "json_directory = '/Users/isaacbevers/sensein/reproschema-wrapper/b2aiprotocol'\n",
    "field_names = ['question', 'preamble', 'name']\n",
    "file_fields = find_fields_in_directory(json_directory, field_names)\n",
    "\n",
    "check_file_path = 'parsed_redcap_pdfs.txt'\n",
    "filtered_fields = filter_fields_not_in_file(file_fields, check_file_path)\n",
    "\n",
    "filtered_fields_output = 'filtered_fields.json'\n",
    "with open(filtered_fields_output, 'w', encoding='utf-8') as f:\n",
    "    json.dump(filtered_fields, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print the filtered fields\n",
    "for file_path, fields in filtered_fields.items():\n",
    "    print(f\"{file_path}: {fields}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
