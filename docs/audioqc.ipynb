{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load derivatives\n",
    "# randomly label\n",
    "# feature selection\n",
    "# train RFC\n",
    "# train dual loop LOO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Training Process:\n",
    "```\n",
    "For each site (Outer Loop - Leave-One-Site-Out Cross-Validation):\n",
    "    Hold out one site as the test set\n",
    "    Train on the remaining N-1 sites\n",
    "\n",
    "    For each hyperparameter configuration (Inner Loop - Grid/Random Search):\n",
    "        Select a combination of:\n",
    "            - Preprocessing method (normalization + feature selection)\n",
    "            - Model type (SVC-lin, SVC-rbf, RFC)\n",
    "            - Classifier hyperparameters (C, gamma, tree depth, etc.)\n",
    "\n",
    "        For each fold in cross-validation (Inner Loop - Cross-Validation):\n",
    "            Split the training data into train/validation folds\n",
    "            Train the model on the training fold\n",
    "            Evaluate on the validation fold\n",
    "        \n",
    "        Select the best preprocessing/model configuration based on average validation performance\n",
    "\n",
    "    Train the final model with the best hyperparameters & preprocessing on all N-1 training sites\n",
    "    Evaluate on the held-out site\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12523, 133)\n",
      "0 participant\n",
      "1 task\n",
      "2 F0semitoneFrom27.5Hz_sma3nz_amean\n",
      "3 F0semitoneFrom27.5Hz_sma3nz_stddevNorm\n",
      "4 F0semitoneFrom27.5Hz_sma3nz_percentile20.0\n",
      "5 F0semitoneFrom27.5Hz_sma3nz_percentile50.0\n",
      "6 F0semitoneFrom27.5Hz_sma3nz_percentile80.0\n",
      "7 F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2\n",
      "8 F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope\n",
      "9 F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope\n",
      "10 F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope\n",
      "11 F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope\n",
      "12 loudness_sma3_amean\n",
      "13 loudness_sma3_stddevNorm\n",
      "14 loudness_sma3_percentile20.0\n",
      "15 loudness_sma3_percentile50.0\n",
      "16 loudness_sma3_percentile80.0\n",
      "17 loudness_sma3_pctlrange0-2\n",
      "18 loudness_sma3_meanRisingSlope\n",
      "19 loudness_sma3_stddevRisingSlope\n",
      "20 loudness_sma3_meanFallingSlope\n",
      "21 loudness_sma3_stddevFallingSlope\n",
      "22 spectralFlux_sma3_amean\n",
      "23 spectralFlux_sma3_stddevNorm\n",
      "24 mfcc1_sma3_amean\n",
      "25 mfcc1_sma3_stddevNorm\n",
      "26 mfcc2_sma3_amean\n",
      "27 mfcc2_sma3_stddevNorm\n",
      "28 mfcc3_sma3_amean\n",
      "29 mfcc3_sma3_stddevNorm\n",
      "30 mfcc4_sma3_amean\n",
      "31 mfcc4_sma3_stddevNorm\n",
      "32 jitterLocal_sma3nz_amean\n",
      "33 jitterLocal_sma3nz_stddevNorm\n",
      "34 shimmerLocaldB_sma3nz_amean\n",
      "35 shimmerLocaldB_sma3nz_stddevNorm\n",
      "36 HNRdBACF_sma3nz_amean\n",
      "37 HNRdBACF_sma3nz_stddevNorm\n",
      "38 logRelF0-H1-H2_sma3nz_amean\n",
      "39 logRelF0-H1-H2_sma3nz_stddevNorm\n",
      "40 logRelF0-H1-A3_sma3nz_amean\n",
      "41 logRelF0-H1-A3_sma3nz_stddevNorm\n",
      "42 F1frequency_sma3nz_amean\n",
      "43 F1frequency_sma3nz_stddevNorm\n",
      "44 F1bandwidth_sma3nz_amean\n",
      "45 F1bandwidth_sma3nz_stddevNorm\n",
      "46 F1amplitudeLogRelF0_sma3nz_amean\n",
      "47 F1amplitudeLogRelF0_sma3nz_stddevNorm\n",
      "48 F2frequency_sma3nz_amean\n",
      "49 F2frequency_sma3nz_stddevNorm\n",
      "50 F2bandwidth_sma3nz_amean\n",
      "51 F2bandwidth_sma3nz_stddevNorm\n",
      "52 F2amplitudeLogRelF0_sma3nz_amean\n",
      "53 F2amplitudeLogRelF0_sma3nz_stddevNorm\n",
      "54 F3frequency_sma3nz_amean\n",
      "55 F3frequency_sma3nz_stddevNorm\n",
      "56 F3bandwidth_sma3nz_amean\n",
      "57 F3bandwidth_sma3nz_stddevNorm\n",
      "58 F3amplitudeLogRelF0_sma3nz_amean\n",
      "59 F3amplitudeLogRelF0_sma3nz_stddevNorm\n",
      "60 alphaRatioV_sma3nz_amean\n",
      "61 alphaRatioV_sma3nz_stddevNorm\n",
      "62 hammarbergIndexV_sma3nz_amean\n",
      "63 hammarbergIndexV_sma3nz_stddevNorm\n",
      "64 slopeV0-500_sma3nz_amean\n",
      "65 slopeV0-500_sma3nz_stddevNorm\n",
      "66 slopeV500-1500_sma3nz_amean\n",
      "67 slopeV500-1500_sma3nz_stddevNorm\n",
      "68 spectralFluxV_sma3nz_amean\n",
      "69 spectralFluxV_sma3nz_stddevNorm\n",
      "70 mfcc1V_sma3nz_amean\n",
      "71 mfcc1V_sma3nz_stddevNorm\n",
      "72 mfcc2V_sma3nz_amean\n",
      "73 mfcc2V_sma3nz_stddevNorm\n",
      "74 mfcc3V_sma3nz_amean\n",
      "75 mfcc3V_sma3nz_stddevNorm\n",
      "76 mfcc4V_sma3nz_amean\n",
      "77 mfcc4V_sma3nz_stddevNorm\n",
      "78 alphaRatioUV_sma3nz_amean\n",
      "79 hammarbergIndexUV_sma3nz_amean\n",
      "80 slopeUV0-500_sma3nz_amean\n",
      "81 slopeUV500-1500_sma3nz_amean\n",
      "82 spectralFluxUV_sma3nz_amean\n",
      "83 loudnessPeaksPerSec\n",
      "84 VoicedSegmentsPerSec\n",
      "85 MeanVoicedSegmentLengthSec\n",
      "86 StddevVoicedSegmentLengthSec\n",
      "87 MeanUnvoicedSegmentLength\n",
      "88 StddevUnvoicedSegmentLength\n",
      "89 equivalentSoundLevel_dBp\n",
      "90 duration\n",
      "91 speaking_rate\n",
      "92 articulation_rate\n",
      "93 phonation_ratio\n",
      "94 pause_rate\n",
      "95 mean_pause_duration\n",
      "96 mean_f0_hertz\n",
      "97 std_f0_hertz\n",
      "98 mean_intensity_db\n",
      "99 std_intensity_db\n",
      "100 range_ratio_intensity_db\n",
      "101 mean_hnr_db\n",
      "102 std_hnr_db\n",
      "103 spectral_slope\n",
      "104 spectral_tilt\n",
      "105 cepstral_peak_prominence_mean\n",
      "106 cepstral_peak_prominence_std\n",
      "107 mean_f1_loc\n",
      "108 std_f1_loc\n",
      "109 mean_b1_loc\n",
      "110 std_b1_loc\n",
      "111 mean_f2_loc\n",
      "112 std_f2_loc\n",
      "113 mean_b2_loc\n",
      "114 std_b2_loc\n",
      "115 spectral_gravity\n",
      "116 spectral_std_dev\n",
      "117 spectral_skewness\n",
      "118 spectral_kurtosis\n",
      "119 local_jitter\n",
      "120 localabsolute_jitter\n",
      "121 rap_jitter\n",
      "122 ppq5_jitter\n",
      "123 ddp_jitter\n",
      "124 local_shimmer\n",
      "125 localDB_shimmer\n",
      "126 apq3_shimmer\n",
      "127 apq5_shimmer\n",
      "128 apq11_shimmer\n",
      "129 dda_shimmer\n",
      "130 stoi\n",
      "131 pesq\n",
      "132 si_sdr\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV file\n",
    "features_df = pd.read_csv(\"/Users/isaacbevers/sensein/b2ai-wrapper/b2ai-data/bridge2ai-voice-corpus-3/derived/static_features.csv\")  # Replace \"file.csv\" with your actual file path\n",
    "\n",
    "# Display the first few rows\n",
    "print(features_df.shape)\n",
    "\n",
    "\n",
    "for i, col in enumerate(features_features_df.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 1055)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenotype_df = pd.read_csv(\"/Users/isaacbevers/sensein/b2ai-wrapper/b2ai-data/bridge2ai-voice-corpus-3/derived/phenotype.tsv\", sep='\\t')\n",
    "phenotype_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1151)\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['record_id', 'redcap_repeat_instrument', 'redcap_repeat_instance',\n",
       "       'selected_language', 'consent_status', 'is_feasibility_participant',\n",
       "       'enrollment_institution', 'age', 'eligible_studies___1',\n",
       "       'eligible_studies___2',\n",
       "       ...\n",
       "       'vocabulary_item_word_4', 'vocabulary_item_difficulty_4',\n",
       "       'vocabulary_item_word_5', 'vocabulary_item_difficulty_5',\n",
       "       'vocabulary_item_word_6', 'vocabulary_item_difficulty_6',\n",
       "       'random_session_id', 'random_recording_acoustic_task_id',\n",
       "       'random_duration', 'random_item_generation_category'],\n",
       "      dtype='object', length=1151)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participants_df = pd.read_csv(\"/Users/isaacbevers/sensein/b2ai-wrapper/b2ai-data/bridge2ai-voice-corpus-3/bids/bids/participants.tsv\", sep=\"\\t\")\n",
    "print(participants_df.shape)\n",
    "print(\"session_site\" in participants_df.columns)\n",
    "participants_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12523, 134)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_to_site = dict(zip(participants_df[\"record_id\"], participants_df[\"session_site\"]))\n",
    "features_df[\"site\"] = features_df[\"participant\"].map(participant_to_site)\n",
    "features_only_df = features_df.drop(columns=['site', 'participant', 'task'])  # Exclude non-feature columns\n",
    "features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The first preprocessing step is a site-wise normalization of features. For robustness, this normalization calculates a center (as the median feature value) and a spread (as the interquartile range) per feature for demeaning and scaling data. This filter can center only, scale only or perform both centering and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site-wise normalization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def site_wise_normalization(features_df, features, site_column, mode=\"both\"):\n",
    "    \"\"\"\n",
    "    Perform site-wise normalization using median and interquartile range (IQR).\n",
    "    \n",
    "    Args:\n",
    "        features_df (pd.DataFrame): The dataset including site information.\n",
    "        features (pd.DataFrame): The feature columns to normalize.\n",
    "        site_column (str): The column representing site labels.\n",
    "        mode (str): 'center', 'scale', or 'both' (default).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Normalized feature DataFrame.\n",
    "    \"\"\"\n",
    "    normalized_features = features.copy()\n",
    "\n",
    "    for site in features_df[site_column].unique():\n",
    "        site_mask = features_df[site_column] == site\n",
    "        site_data = features[site_mask]\n",
    "\n",
    "        median = site_data.median()\n",
    "        iqr = site_data.quantile(0.75) - site_data.quantile(0.25)  # Interquartile Range (IQR)\n",
    "\n",
    "        if mode == \"center\":\n",
    "            normalized_features.loc[site_mask] = site_data - median\n",
    "        elif mode == \"scale\":\n",
    "            normalized_features.loc[site_mask] = site_data / iqr\n",
    "        elif mode == \"both\":\n",
    "            normalized_features.loc[site_mask] = (site_data - median) / iqr\n",
    "\n",
    "    return normalized_features\n",
    "\n",
    "# Define site column and feature columns\n",
    "site_column = 'site'\n",
    "features_normalized_center = site_wise_normalization(features_df, features_only_df, site_column='site', mode='center')\n",
    "features_normalized_scale = site_wise_normalization(features_df, features_only_df, site_column='site', mode='scale')\n",
    "features_normalized_both = site_wise_normalization(features_df, features_only_df, site_column='site', mode='both')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The second preprocessing step available is a dimensionality reduction filter excluding features highly predictive of the site of origin of data points. To do so, we fit a classifier based on extremely randomized trees [39], where the variables are the features and the responses are the sites of acquisition. We iteratively fit the classifier and remove the feature most predictive of the site at each step, until certain convergence criteria is met (either a maximum number of features to remove is reached or the performance of the classifier is very low and thus the remaining features do not predict the site at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial site prediction accuracy: 0.79\n",
      "Iteration 1: Removed 'mfcc2_sma3_amean', New Accuracy: 0.78\n",
      "Iteration 2: Removed 'mfcc3_sma3_amean', New Accuracy: 0.78\n",
      "Iteration 3: Removed 'mfcc2V_sma3nz_amean', New Accuracy: 0.77\n",
      "Iteration 4: Removed 'slopeUV0-500_sma3nz_amean', New Accuracy: 0.76\n",
      "Iteration 5: Removed 'mfcc1V_sma3nz_amean', New Accuracy: 0.75\n",
      "Iteration 6: Removed 'slopeUV500-1500_sma3nz_amean', New Accuracy: 0.75\n",
      "Iteration 7: Removed 'mfcc1_sma3_amean', New Accuracy: 0.74\n",
      "Iteration 8: Removed 'mfcc3V_sma3nz_amean', New Accuracy: 0.73\n",
      "Iteration 9: Removed 'loudness_sma3_percentile20.0', New Accuracy: 0.72\n",
      "Iteration 10: Removed 'equivalentSoundLevel_dBp', New Accuracy: 0.72\n",
      "Iteration 11: Removed 'alphaRatioUV_sma3nz_amean', New Accuracy: 0.71\n",
      "Iteration 12: Removed 'hammarbergIndexUV_sma3nz_amean', New Accuracy: 0.71\n",
      "Iteration 13: Removed 'spectralFlux_sma3_amean', New Accuracy: 0.71\n",
      "Iteration 14: Removed 'spectralFluxUV_sma3nz_amean', New Accuracy: 0.71\n",
      "Iteration 15: Removed 'mfcc4_sma3_amean', New Accuracy: 0.70\n",
      "Iteration 16: Removed 'mfcc2_sma3_stddevNorm', New Accuracy: 0.69\n",
      "Iteration 17: Removed 'loudness_sma3_amean', New Accuracy: 0.69\n",
      "Iteration 18: Removed 'spectralFlux_sma3_stddevNorm', New Accuracy: 0.69\n",
      "Iteration 19: Removed 'loudness_sma3_percentile80.0', New Accuracy: 0.69\n",
      "Iteration 20: Removed 'loudness_sma3_pctlrange0-2', New Accuracy: 0.68\n",
      "Iteration 21: Removed 'loudness_sma3_meanRisingSlope', New Accuracy: 0.69\n",
      "Iteration 22: Removed 'loudness_sma3_stddevRisingSlope', New Accuracy: 0.68\n",
      "Iteration 23: Removed 'loudness_sma3_percentile50.0', New Accuracy: 0.68\n",
      "Iteration 24: Removed 'loudness_sma3_meanFallingSlope', New Accuracy: 0.67\n",
      "Iteration 25: Removed 'loudness_sma3_stddevFallingSlope', New Accuracy: 0.67\n",
      "Iteration 26: Removed 'mfcc3_sma3_stddevNorm', New Accuracy: 0.66\n",
      "Iteration 27: Removed 'mfcc1_sma3_stddevNorm', New Accuracy: 0.66\n",
      "Iteration 28: Removed 'loudness_sma3_stddevNorm', New Accuracy: 0.65\n",
      "Iteration 29: Removed 'mfcc4_sma3_stddevNorm', New Accuracy: 0.65\n",
      "Iteration 30: Removed 'loudnessPeaksPerSec', New Accuracy: 0.64\n",
      "Iteration 31: Removed 'MeanUnvoicedSegmentLength', New Accuracy: 0.66\n",
      "Iteration 32: Removed 'spectralFluxV_sma3nz_amean', New Accuracy: 0.65\n",
      "Iteration 33: Removed 'slopeV0-500_sma3nz_amean', New Accuracy: 0.65\n",
      "Iteration 34: Removed 'mfcc1V_sma3nz_stddevNorm', New Accuracy: 0.64\n",
      "Iteration 35: Removed 'logRelF0-H1-A3_sma3nz_amean', New Accuracy: 0.64\n",
      "Iteration 36: Removed 'hammarbergIndexV_sma3nz_amean', New Accuracy: 0.64\n",
      "Iteration 37: Removed 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0', New Accuracy: 0.63\n",
      "Iteration 38: Removed 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0', New Accuracy: 0.63\n",
      "Iteration 39: Removed 'F0semitoneFrom27.5Hz_sma3nz_amean', New Accuracy: 0.62\n",
      "Iteration 40: Removed 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0', New Accuracy: 0.61\n",
      "Iteration 41: Removed 'HNRdBACF_sma3nz_amean', New Accuracy: 0.61\n",
      "Iteration 42: Removed 'logRelF0-H1-H2_sma3nz_amean', New Accuracy: 0.60\n",
      "Iteration 43: Removed 'mfcc4V_sma3nz_amean', New Accuracy: 0.60\n",
      "Iteration 44: Removed 'F1frequency_sma3nz_amean', New Accuracy: 0.60\n",
      "Iteration 45: Removed 'F3frequency_sma3nz_amean', New Accuracy: 0.60\n",
      "Iteration 46: Removed 'mfcc2V_sma3nz_stddevNorm', New Accuracy: 0.60\n",
      "Iteration 47: Removed 'F2bandwidth_sma3nz_amean', New Accuracy: 0.60\n",
      "Iteration 48: Removed 'slopeV500-1500_sma3nz_amean', New Accuracy: 0.59\n",
      "Iteration 49: Removed 'F1frequency_sma3nz_stddevNorm', New Accuracy: 0.59\n",
      "Iteration 50: Removed 'shimmerLocaldB_sma3nz_stddevNorm', New Accuracy: 0.58\n",
      "Iteration 51: Removed 'F2frequency_sma3nz_amean', New Accuracy: 0.58\n",
      "Iteration 52: Removed 'alphaRatioV_sma3nz_amean', New Accuracy: 0.58\n",
      "Iteration 53: Removed 'F1bandwidth_sma3nz_amean', New Accuracy: 0.58\n",
      "Iteration 54: Removed 'F3bandwidth_sma3nz_amean', New Accuracy: 0.58\n",
      "Iteration 55: Removed 'shimmerLocaldB_sma3nz_amean', New Accuracy: 0.57\n",
      "Iteration 56: Removed 'VoicedSegmentsPerSec', New Accuracy: 0.57\n",
      "Iteration 57: Removed 'StddevUnvoicedSegmentLength', New Accuracy: 0.57\n",
      "Iteration 58: Removed 'mfcc3V_sma3nz_stddevNorm', New Accuracy: 0.57\n",
      "Iteration 59: Removed 'F2bandwidth_sma3nz_stddevNorm', New Accuracy: 0.57\n",
      "Iteration 60: Removed 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm', New Accuracy: 0.57\n",
      "Iteration 61: Removed 'HNRdBACF_sma3nz_stddevNorm', New Accuracy: 0.56\n",
      "Iteration 62: Removed 'F2amplitudeLogRelF0_sma3nz_amean', New Accuracy: 0.56\n",
      "Iteration 63: Removed 'F3amplitudeLogRelF0_sma3nz_amean', New Accuracy: 0.57\n",
      "Iteration 64: Removed 'F1amplitudeLogRelF0_sma3nz_amean', New Accuracy: 0.56\n",
      "Iteration 65: Removed 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2', New Accuracy: 0.57\n",
      "Iteration 66: Removed 'F2frequency_sma3nz_stddevNorm', New Accuracy: 0.56\n",
      "Iteration 67: Removed 'F3amplitudeLogRelF0_sma3nz_stddevNorm', New Accuracy: 0.56\n",
      "Final removed features: ['mfcc2_sma3_amean', 'mfcc3_sma3_amean', 'mfcc2V_sma3nz_amean', 'slopeUV0-500_sma3nz_amean', 'mfcc1V_sma3nz_amean', 'slopeUV500-1500_sma3nz_amean', 'mfcc1_sma3_amean', 'mfcc3V_sma3nz_amean', 'loudness_sma3_percentile20.0', 'equivalentSoundLevel_dBp', 'alphaRatioUV_sma3nz_amean', 'hammarbergIndexUV_sma3nz_amean', 'spectralFlux_sma3_amean', 'spectralFluxUV_sma3nz_amean', 'mfcc4_sma3_amean', 'mfcc2_sma3_stddevNorm', 'loudness_sma3_amean', 'spectralFlux_sma3_stddevNorm', 'loudness_sma3_percentile80.0', 'loudness_sma3_pctlrange0-2', 'loudness_sma3_meanRisingSlope', 'loudness_sma3_stddevRisingSlope', 'loudness_sma3_percentile50.0', 'loudness_sma3_meanFallingSlope', 'loudness_sma3_stddevFallingSlope', 'mfcc3_sma3_stddevNorm', 'mfcc1_sma3_stddevNorm', 'loudness_sma3_stddevNorm', 'mfcc4_sma3_stddevNorm', 'loudnessPeaksPerSec', 'MeanUnvoicedSegmentLength', 'spectralFluxV_sma3nz_amean', 'slopeV0-500_sma3nz_amean', 'mfcc1V_sma3nz_stddevNorm', 'logRelF0-H1-A3_sma3nz_amean', 'hammarbergIndexV_sma3nz_amean', 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0', 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0', 'F0semitoneFrom27.5Hz_sma3nz_amean', 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0', 'HNRdBACF_sma3nz_amean', 'logRelF0-H1-H2_sma3nz_amean', 'mfcc4V_sma3nz_amean', 'F1frequency_sma3nz_amean', 'F3frequency_sma3nz_amean', 'mfcc2V_sma3nz_stddevNorm', 'F2bandwidth_sma3nz_amean', 'slopeV500-1500_sma3nz_amean', 'F1frequency_sma3nz_stddevNorm', 'shimmerLocaldB_sma3nz_stddevNorm', 'F2frequency_sma3nz_amean', 'alphaRatioV_sma3nz_amean', 'F1bandwidth_sma3nz_amean', 'F3bandwidth_sma3nz_amean', 'shimmerLocaldB_sma3nz_amean', 'VoicedSegmentsPerSec', 'StddevUnvoicedSegmentLength', 'mfcc3V_sma3nz_stddevNorm', 'F2bandwidth_sma3nz_stddevNorm', 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm', 'HNRdBACF_sma3nz_stddevNorm', 'F2amplitudeLogRelF0_sma3nz_amean', 'F3amplitudeLogRelF0_sma3nz_amean', 'F1amplitudeLogRelF0_sma3nz_amean', 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2', 'F2frequency_sma3nz_stddevNorm', 'F3amplitudeLogRelF0_sma3nz_stddevNorm']\n",
      "Final site prediction accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = features_df.drop(columns=['site', 'participant', 'task'])  # Drop non-AQM columns\n",
    "y = features_df['site']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train initial ExtraTreesClassifier to predict site labels\n",
    "site_predictor = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "site_predictor.fit(X_train, y_train)\n",
    "\n",
    "# Get initial accuracy (baseline)\n",
    "initial_accuracy = site_predictor.score(X_test, y_test)\n",
    "print(f\"Initial site prediction accuracy: {initial_accuracy:.2f}\")\n",
    "\n",
    "# Define stopping criteria\n",
    "num_sites = len(np.unique(y))  # Number of unique sites\n",
    "chance_level = 1 / num_sites  # Random guessing accuracy\n",
    "max_removals = 131 - 64  # Set a maximum number of features to remove (total features - MRIqc number)\n",
    "\n",
    "# Start feature elimination loop\n",
    "features_to_remove = []\n",
    "iteration = 0\n",
    "\n",
    "while iteration < max_removals:\n",
    "    # Get feature importances\n",
    "    feature_importances = site_predictor.feature_importances_\n",
    "    \n",
    "    # Identify the most predictive feature\n",
    "    most_predictive_feature = X_train.columns[np.argmax(feature_importances)]\n",
    "    features_to_remove.append(most_predictive_feature)\n",
    "\n",
    "    # Remove the most predictive feature from the dataset\n",
    "    X_train = X_train.drop(columns=[most_predictive_feature])\n",
    "    X_test = X_test.drop(columns=[most_predictive_feature])\n",
    "\n",
    "    # Retrain the classifier without the removed feature\n",
    "    site_predictor = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "    site_predictor.fit(X_train, y_train)\n",
    "\n",
    "    # Get new accuracy\n",
    "    new_accuracy = site_predictor.score(X_test, y_test)\n",
    "    print(f\"Iteration {iteration + 1}: Removed '{most_predictive_feature}', New Accuracy: {new_accuracy:.2f}\")\n",
    "\n",
    "    # Check stopping conditions\n",
    "    if new_accuracy <= chance_level:\n",
    "        print(\"Stopping: Site prediction accuracy is near chance level.\")\n",
    "        break\n",
    "\n",
    "    iteration += 1\n",
    "\n",
    "print(f\"Final removed features: {features_to_remove}\")\n",
    "print(f\"Final site prediction accuracy: {new_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finally, a third preprocessing step implements the Winnow algorithm [40] using extremely randomized trees in a similar way to the previous filter, but comparing features to a synthetic, randomly-generated feature. This feature selection filter removes those IQMs below a certain SNR level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 35 low-SNR features.\n",
      "Removed 32 low-SNR features.\n",
      "Removed 38 low-SNR features.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "def winnow_feature_selection(X, y, snr_threshold=1.0):\n",
    "    \"\"\"\n",
    "    Perform Winnow-based feature selection using ExtraTreesClassifier.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Feature matrix.\n",
    "        y (pd.Series): Target labels (e.g., site).\n",
    "        snr_threshold (float): Minimum SNR threshold for feature retention.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Reduced feature set with low SNR features removed.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Generate a synthetic random feature (noise)\n",
    "    np.random.seed(42)\n",
    "    X[\"random_noise\"] = np.random.normal(0, 1, size=len(X))\n",
    "\n",
    "    # Train ExtraTreesClassifier to measure feature importance\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importances = clf.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Identify the importance of the synthetic feature (random noise)\n",
    "    random_feature_importance = feature_importances[X.columns.get_loc(\"random_noise\")]\n",
    "\n",
    "    # Compute SNR for each feature (ratio of feature importance to random noise importance)\n",
    "    snr = feature_importances / random_feature_importance\n",
    "\n",
    "    # Select features where SNR exceeds the threshold\n",
    "    selected_features = feature_names[snr > snr_threshold].tolist()\n",
    "\n",
    "    # Avoid ValueError: Only remove \"random_noise\" if it exists\n",
    "    if \"random_noise\" in selected_features:\n",
    "        selected_features.remove(\"random_noise\")\n",
    "\n",
    "    print(f\"Removed {X.shape[1] - len(selected_features)} low-SNR features.\")\n",
    "    \n",
    "    return X[selected_features]\n",
    "\n",
    "\n",
    "# Apply Winnow feature selection for each normalization method\n",
    "features_selected_center = winnow_feature_selection(features_normalized_center, features_df[\"site\"])\n",
    "features_selected_scale = winnow_feature_selection(features_normalized_scale, features_df[\"site\"])\n",
    "features_selected_both = winnow_feature_selection(features_normalized_both, features_df[\"site\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, column_name=\"label\", labels=[\"accept\", \"exclude\", \"unsure\"], random_seed=None):\n",
    "    \"\"\"\n",
    "    Adds a column with randomly assigned labels to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to modify.\n",
    "    - column_name (str): Name of the new column (default: \"label\").\n",
    "    - labels (list): List of labels to sample from (default: [\"accept\", \"exclude\", \"unsure\"]).\n",
    "    - random_seed (int or None): Random seed for reproducibility (default: None).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Modified DataFrame with the new column.\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)  # Set random seed for reproducibility\n",
    "\n",
    "    df[column_name] = np.random.choice(labels, size=len(df))\n",
    "    return df\n",
    "\n",
    "features_selected_center = add_labels(features_selected_center)\n",
    "features_selected_scale = add_labels(features_selected_scale)\n",
    "features_normalized_both = add_labels(features_normalized_both)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">A support-vector machine [37] finds a hyperplane in the high-dimensional space of the features that robustly separates the classes of interest. The SVC then uses the hyperplane to decide the class that is assigned to new samples in the space of features. Two hyper-parameters define the support-vector machine algorithm: a kernel function that defines the similarity between data points to ultimately compute a distance to the hyperplane, and a regularization weight C. In particular, we analyzed here the linear SVC implementation (as of now, “SVC-lin”) and the one based on radial basis functions (denoted by “SVC-rbf”). During model selection, we evaluated the regularization weight C of both SVC and the γ parameter (kernel width) particular to the SVC-rbf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values detected in features. Imputing missing values...\n",
      "Best Linear SVC (C=10), Test Accuracy: 0.3269\n",
      "Best RBF SVC (C=0.1, gamma=1), Test Accuracy: 0.3397\n",
      "Warning: NaN values detected in features. Imputing missing values...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def train_svm_for_label_prediction(features_df, label_column=\"label\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Trains Support Vector Machines (SVM) with hyperparameter tuning to predict labels ('accept', 'exclude', 'unsure').\n",
    "\n",
    "    Parameters:\n",
    "    - features_df (pd.DataFrame): DataFrame containing features and the label column.\n",
    "    - label_column (str): Name of the column containing classification labels (default: \"label\").\n",
    "    - test_size (float): Fraction of data to use for testing (default: 0.2).\n",
    "    - random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Contains best models and their test accuracies.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure label column exists\n",
    "    if label_column not in features_df.columns:\n",
    "        raise ValueError(f\"Label column '{label_column}' not found in DataFrame.\")\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = features_df.drop(columns=[label_column])  # Features\n",
    "    y = features_df[label_column]  # Labels\n",
    "\n",
    "    # Check for NaN values\n",
    "    if X.isna().sum().sum() > 0:\n",
    "        print(\"Warning: NaN values detected in features. Imputing missing values...\")\n",
    "        imputer = SimpleImputer(strategy=\"mean\")  # Fill NaN with mean of the column\n",
    "        X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Split dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Standardize features (SVM performs better with standardized inputs)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define hyperparameter grids for linear SVC and RBF SVC\n",
    "    param_grid_lin = {'C': [0.1, 1, 10, 100]}\n",
    "    param_grid_rbf = {'C': [0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "    # Perform Grid Search for Linear SVC\n",
    "    grid_search_lin = GridSearchCV(SVC(kernel=\"linear\"), param_grid_lin, cv=5, scoring=\"accuracy\")\n",
    "    grid_search_lin.fit(X_train_scaled, y_train)\n",
    "    best_svc_lin = grid_search_lin.best_estimator_\n",
    "\n",
    "    # Perform Grid Search for RBF SVC\n",
    "    grid_search_rbf = GridSearchCV(SVC(kernel=\"rbf\"), param_grid_rbf, cv=5, scoring=\"accuracy\")\n",
    "    grid_search_rbf.fit(X_train_scaled, y_train)\n",
    "    best_svc_rbf = grid_search_rbf.best_estimator_\n",
    "\n",
    "    # Evaluate the best models on test set\n",
    "    y_pred_lin = best_svc_lin.predict(X_test_scaled)\n",
    "    y_pred_rbf = best_svc_rbf.predict(X_test_scaled)\n",
    "\n",
    "    acc_lin = accuracy_score(y_test, y_pred_lin)\n",
    "    acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best Linear SVC (C={grid_search_lin.best_params_['C']}), Test Accuracy: {acc_lin:.4f}\")\n",
    "    print(f\"Best RBF SVC (C={grid_search_rbf.best_params_['C']}, gamma={grid_search_rbf.best_params_['gamma']}), Test Accuracy: {acc_rbf:.4f}\")\n",
    "\n",
    "    # Return best models and accuracies\n",
    "    return {\n",
    "        \"best_linear_svc\": best_svc_lin,\n",
    "        \"best_rbf_svc\": best_svc_rbf,\n",
    "        \"accuracy_linear\": acc_lin,\n",
    "        \"accuracy_rbf\": acc_rbf\n",
    "    }\n",
    "\n",
    "# Example Usage on Labeled Feature Sets\n",
    "results_center = train_svm_for_label_prediction(features_selected_center)\n",
    "results_scale = train_svm_for_label_prediction(features_selected_scale)\n",
    "results_both = train_svm_for_label_prediction(features_normalized_both)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def train_random_forest(features_df, label_column=\"label\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest Classifier (RFC) with hyperparameter tuning using GridSearchCV.\n",
    "\n",
    "    Parameters:\n",
    "    - features_df (pd.DataFrame): DataFrame containing features and the label column.\n",
    "    - label_column (str): Name of the column containing classification labels (default: \"label\").\n",
    "    - test_size (float): Fraction of data to use for testing (default: 0.2).\n",
    "    - random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Contains best model and its test accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure label column exists\n",
    "    if label_column not in features_df.columns:\n",
    "        raise ValueError(f\"Label column '{label_column}' not found in DataFrame.\")\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = features_df.drop(columns=[label_column])  # Features\n",
    "    y = features_df[label_column]  # Labels\n",
    "\n",
    "    # Check for NaN values and impute missing data\n",
    "    if X.isna().sum().sum() > 0:\n",
    "        print(\"Warning: NaN values detected in features. Imputing missing values...\")\n",
    "        imputer = SimpleImputer(strategy=\"mean\")  # Fill NaN with mean of the column\n",
    "        X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Split dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Standardize features (optional for tree-based models, but helps when combined with other models)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define hyperparameter grid for Random Forest\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [50, 100, 200],  # Number of trees\n",
    "        \"max_depth\": [None, 10, 20],  # Maximum depth of trees\n",
    "        \"min_samples_split\": [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "        \"min_samples_leaf\": [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    }\n",
    "\n",
    "    # Perform Grid Search for Random Forest\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=random_state), param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    best_rfc = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best model on test set\n",
    "    y_pred = best_rfc.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Best Random Forest Model: {grid_search.best_params_}, Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "    # Return best model and accuracy\n",
    "    return {\n",
    "        \"best_rfc\": best_rfc,\n",
    "        \"accuracy\": acc\n",
    "    }\n",
    "\n",
    "# Example Usage on Labeled Feature Sets\n",
    "results_center = train_random_forest(features_selected_center)\n",
    "results_scale = train_random_forest(features_selected_scale)\n",
    "results_both = train_random_forest(features_normalized_both)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b2ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
