{
  "fields": [
    {
      "name": "participant_id",
      "type": "string",
      "description": "Unique identifier for each participant."
    },
    {
      "name": "session_id",
      "type": "string",
      "description": "Unique identifier for each session."
    },
    {
      "name": "task_name",
      "type": "string",
      "description": "The audio task conducted for the recording."
    },
    {
      "name": "n_frames",
      "type": "integer",
      "description": "Number of time frames in the PPG tensor (variable per recording)."
    },
    {
      "name": "ppg",
      "type": "array",
      "description": "Phonetic posteriorgram probabilities across 40 phoneme categories.",
      "extras": {
        "tensor": {
          "dtype": "float32",
          "ndim": 2,
          "dims": ["phoneme", "time"],
          "shape": [40, null],

          "axis": {
            "phoneme": {
              "description": "Index over the 40 phoneme categories defined by the PPG model.",
              "labels": [
                "aa","ae","ah","ao","aw","ay",
                "b","ch","d","dh",
                "eh","er","ey",
                "f","g",
                "hh",
                "ih","iy",
                "jh",
                "k",
                "l",
                "m","n","ng",
                "ow","oy",
                "p",
                "r",
                "s","sh",
                "t","th",
                "uh",
                "uw",
                "v",
                "w",
                "y",
                "z",
                "zh",
                "silence"
              ]
            },
            "time": {
              "sampling_rate_hz": 100,
              "description": "Temporal resolution of the PPG sequence, matched to the acoustic frame rate produced by the default model."
            }
          },

          "units": "probability",
          "value_range": [0.0, 1.0],
          "notes": "Each time frame contains a normalized probability distribution over the phoneme categories.",

          "config": {
            "sample_rate": 16000
          },

          "provenance": {
            "software": "ppgs",
            "version": "0.0.9",
            "command": "ppgs.from_audio(audio, sample_rate=16000)",

            "software_reference": {
              "title": "High-Fidelity Neural Phonetic Posteriorgrams",
              "authors": "Churchwell, Morrison, and Pardo",
              "venue": "ICASSP 2024 Workshop on Explainable Machine Learning for Speech and Audio",
              "year": 2024,
              "url": "https://arxiv.org/abs/2406.12998"
            },

            "note": "PPG computation is performed using the pretrained neural model with default internal parameters."
          },

          "serialization": {
            "storage": "parquet_nested_list",
            "parquet_type": "list<list<float>>",
            "compression": "zstd"
          }
        }
      }
    }
  ],

  "primaryKey": ["participant_id", "session_id", "task_name"]
}
